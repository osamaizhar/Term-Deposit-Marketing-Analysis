{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Deposit Marketing Prediction Models using LazyPredict\n",
    "\n",
    "This notebook builds two predictive models for term deposit marketing using LazyPredict:\n",
    "1. **Pre-Call Model**: Predicts which customers to call before making any calls (excludes campaign-related features)\n",
    "2. **Post-Call Model**: Predicts which customers to focus on after initial contact (includes all features)\n",
    "\n",
    "We'll compare multiple models using LazyPredict and select the top 3 for each scenario for detailed evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Import LazyPredict for model comparison\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# Import models for detailed evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Set display options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = \"term-deposit-marketing-2020.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(f\"Data loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "df[\"y\"].value_counts(normalize=True).mul(100).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Campaign-Related Features\n",
    "\n",
    "For our first model, we need to exclude campaign-related features that would not be available before making calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for each model\n",
    "# Model 1: Pre-call prediction (exclude campaign-related features)\n",
    "model1_features = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact']\n",
    "model1_data = df[model1_features + ['y']].copy()\n",
    "\n",
    "# Model 2: Post-call prediction (include all features)\n",
    "model2_features = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign']\n",
    "model2_data = df[model2_features + ['y']].copy()\n",
    "\n",
    "print(f\"Features for Model 1 (pre-call):\\n {model1_features}\\n\")\n",
    "print(f\"Features for Model 2 (post-call):\\n {model2_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data for Model 1 (Pre-Call Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Model 1\n",
    "# Convert target to binary\n",
    "model1_data[\"y_binary\"] = model1_data[\"y\"].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# Split features and target\n",
    "X1 = model1_data.drop([\"y\", \"y_binary\"], axis=1)\n",
    "y1 = model1_data[\"y_binary\"]\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = X1.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numerical_features = X1.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "print(f\"Categorical features: {categorical_features}\")\n",
    "print(f\"Numerical features: {numerical_features}\")\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "numerical_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "preprocessor1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Split data into train and test sets\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(\n",
    "    X1, y1, test_size=0.2, random_state=42, stratify=y1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model 1: Pre-Call Prediction using LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models with classification report and confusion matrix\n",
    "def evaluate_model(model_name, model, X_train, X_test, y_train, y_test, preprocessor):\n",
    "    # Create pipeline with preprocessing and model\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", model)])\n",
    "\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Classification report\n",
    "    print(f\"\\n{model_name} - Classification Report:\")\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"No\", \"Yes\"],\n",
    "        yticklabels=[\"No\", \"Yes\"],\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = (\n",
    "        2 * (precision * recall) / (precision + recall)\n",
    "        if (precision + recall) > 0\n",
    "        else 0\n",
    "    )\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc:.3f})\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve - {model_name}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nObservations for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"True Positives: {tp} - Correctly predicted subscribers\")\n",
    "    print(f\"False Positives: {fp} - Incorrectly predicted as subscribers\")\n",
    "    print(f\"True Negatives: {tn} - Correctly predicted non-subscribers\")\n",
    "    print(f\"False Negatives: {fn} - Missed potential subscribers\")\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"tp\": tp,\n",
    "        \"fp\": fp,\n",
    "        \"tn\": tn,\n",
    "        \"fn\": fn,\n",
    "        \"pipeline\": pipeline,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LazyPredict to evaluate multiple models for Model 1 (Pre-Call Prediction)\n",
    "print(\"\\n\\nEvaluating models for Model 1 (Pre-Call) using LazyPredict...\")\n",
    "\n",
    "# Create a pipeline with preprocessing\n",
    "pipeline1 = Pipeline(steps=[(\"preprocessor\", preprocessor1)])\n",
    "\n",
    "# Apply preprocessing to the data\n",
    "X1_train_preprocessed = pipeline1.fit_transform(X1_train)\n",
    "X1_test_preprocessed = pipeline1.transform(X1_test)\n",
    "\n",
    "# Initialize LazyClassifier\n",
    "clf1 = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "# Fit and evaluate models\n",
    "models1, predictions1 = clf1.fit(X1_train_preprocessed, X1_test_preprocessed, y1_train, y1_test)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nModel 1 (Pre-Call) - LazyPredict Results:\")\n",
    "display(models1)\n",
    "\n",
    "# Select top 3 models for detailed evaluation\n",
    "top_models1 = models1.head(3).index.tolist()\n",
    "print(f\"\\nTop 3 models for Model 1 (Pre-Call): {top_models1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation of top models\n",
    "results1 = {}\n",
    "for model_name in top_models1:\n",
    "    if model_name == \"LGBMClassifier\":\n",
    "        model = LGBMClassifier(random_state=42)\n",
    "    elif model_name == \"XGBClassifier\":\n",
    "        model = XGBClassifier(random_state=42)\n",
    "    elif model_name == \"RandomForestClassifier\":\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "    elif model_name == \"GradientBoostingClassifier\":\n",
    "        model = GradientBoostingClassifier(random_state=42)\n",
    "    elif model_name == \"DecisionTreeClassifier\":\n",
    "        model = DecisionTreeClassifier(random_state=42)\n",
    "    elif model_name == \"LogisticRegression\":\n",
    "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    elif model_name == \"KNeighborsClassifier\":\n",
    "        model = KNeighborsClassifier()\n",
    "    elif model_name == \"AdaBoostClassifier\":\n",
    "        model = AdaBoostClassifier(random_state=42)\n",
    "    elif model_name == \"SVC\":\n",
    "        model = SVC(probability=True, random_state=42)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n\\nDetailed evaluation of {model_name} for Model 1 (Pre-Call)...\")\n",
    "    result = evaluate_model(model_name, model, X1_train, X1_test, y1_train, y1_test, preprocessor1)\n",
    "    results1[model_name] = result\n",
    "\n",
    "# Add observations about the model performance\n",
    "print(\"\\nObservations for Model 1 (Pre-Call):\")\n",
    "print(\"1. The top-performing models are able to identify patterns in customer data that predict subscription likelihood.\")\n",
    "print(\"2. These models can help the bank prioritize which customers to call, potentially saving resources.\")\n",
    "print(\"3. The models show varying trade-offs between precision and recall, which affects how many potential subscribers might be missed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Data for Model 2 (Post-Call Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Model 2\n",
    "# Convert target to binary\n",
    "model2_data[\"y_binary\"] = model2_data[\"y\"].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# Split features and target\n",
    "X2 = model2_data.drop([\"y\", \"y_binary\"], axis=1)\n",
    "y2 = model2_data[\"y_binary\"]\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features2 = X2.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numerical_features2 = X2.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "print(f\"Categorical features: {categorical_features2}\")\n",
    "print(f\"Numerical features: {numerical_features2}\")\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "categorical_transformer2 = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "numerical_transformer2 = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "preprocessor2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer2, numerical_features2),\n",
    "        (\"cat\", categorical_transformer2, categorical_features2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Split data into train and test sets\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "    X2, y2, test_size=0.2, random_state=42, stratify=y2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 2: Post-Call Prediction using LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LazyPredict to evaluate multiple models for Model 2 (Post-Call Prediction)\n",
    "print(\"\\n\\nEvaluating models for Model 2 (Post-Call) using LazyPredict...\")\n",
    "\n",
    "# Create a pipeline with preprocessing\n",
    "pipeline2 = Pipeline(steps=[(\"preprocessor\", preprocessor2)])\n",
    "\n",
    "# Apply preprocessing to the data\n",
    "X2_train_preprocessed = pipeline2.fit_transform(X2_train)\n",
    "X2_test_preprocessed = pipeline2.transform(X2_test)\n",
    "\n",
    "# Initialize LazyClassifier\n",
    "clf2 = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "# Fit and evaluate models\n",
    "models2, predictions2 = clf2.fit(X2_train_preprocessed, X2_test_preprocessed, y2_train, y2_test)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nModel 2 (Post-Call) - LazyPredict Results:\")\n",
    "display(models2)\n",
    "\n",
    "# Select top 3 models for detailed evaluation\n",
    "top_models2 = models2.head(3).index.tolist()\n",
    "print(f\"\\nTop 3 models for Model 2 (Post-Call): {top_models2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation of top models\n",
    "results2 = {}\n",
    "for model_name in top_models2:\n",
    "    if model_name == \"LGBMClassifier\":\n",
    "        model = LGBMClassifier(random_state=42)\n",
    "    elif model_name == \"XGBClassifier\":\n",
    "        model = XGBClassifier(random_state=42)\n",
    "    elif model_name == \"RandomForestClassifier\":\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "    elif model_name == \"GradientBoostingClassifier\":\n",
    "        model = GradientBoostingClassifier(random_state=42)\n",
    "    elif model_name == \"DecisionTreeClassifier\":\n",
    "        model = DecisionTreeClassifier(random_state=42)\n",
    "    elif model_name == \"LogisticRegression\":\n",
    "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    elif model_name == \"KNeighborsClassifier\":\n",
    "        model = KNeighborsClassifier()\n",
    "    elif model_name == \"AdaBoostClassifier\":\n",
    "        model = AdaBoostClassifier(random_state=42)\n",
    "    elif model_name == \"SVC\":\n",
    "        model = SVC(probability=True, random_state=42)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n\\nDetailed evaluation of {model_name} for Model 2 (Post-Call)...\")\n",
    "    result = evaluate_model(model_name, model, X2_train, X2_test, y2_train, y2_test, preprocessor2)\n",
    "    results2[model_name] = result\n",
    "\n",
    "# Add observations about the model performance\n",
    "print(\"\\nObservations for Model 2 (Post-Call):\")\n",
    "print(\"1. Including campaign-related features significantly improves model performance.\")\n",
    "print(\"2. The 'duration' feature is likely a strong predictor, as it indicates customer interest level.\")\n",
    "print(\"3. These models can help the bank focus follow-up efforts on customers most likely to subscribe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Pre-Call and Post-Call Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the best models from each approach\n",
    "print(\"Comparison of Pre-Call vs Post-Call Models:\\n\")\n",
    "\n",
    "# Create a comparison dataframe\n",
    "comparison_data = []\n",
    "\n",
    "# Add Model 1 (Pre-Call) results\n",
    "for model_name, result in results1.items():\n",
    "    comparison_data.append({\n",
    "        'Model': f\"Pre-Call: {model_name}\",\n",
    "        'Accuracy': result['accuracy'],\n",
    "        'Precision': result['precision'],\n",
    "        'Recall': result['recall'],\n",
    "        'F1 Score': result['f1'],\n",
    "        'ROC AUC': result['roc_auc']\n",
    "    })\n",
    "\n",
    "# Add Model 2 (Post-Call) results\n",
    "for model_name, result in results2.items():\n",
    "    comparison_data.append({\n",
    "        'Model': f\"Post-Call: {model_name}\",\n",
    "        'Accuracy': result['accuracy'],\n",
    "        'Precision': result['precision'],\n",
    "        'Recall': result['recall'],\n",
    "        'F1 Score': result['f1'],\n",
    "        'ROC AUC': result['roc_auc']\n",
    "    })\n",
    "\n",
    "# Create and display comparison dataframe\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df.sort_values('F1 Score', ascending=False, inplace=True)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion and Recommendations\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Pre-Call Model Performance**:\n",
    "   - The top-performing models can identify potential subscribers before making any calls\n",
    "   - These models help prioritize which customers to contact, saving resources\n",
    "   - Performance is limited by not having campaign-related information\n",
    "\n",
    "2. **Post-Call Model Performance**:\n",
    "   - Including campaign-related features significantly improves prediction accuracy\n",
    "   - The 'duration' feature is particularly important, as it indicates customer interest\n",
    "   - These models help focus follow-up efforts on customers most likely to subscribe\n",
    "\n",
    "3. **Comparison**:\n",
    "   - Post-call models consistently outperform pre-call models\n",
    "   - The improvement demonstrates the value of initial contact information\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. **Two-Stage Approach**:\n",
    "   - Use the pre-call model to prioritize initial customer outreach\n",
    "   - After initial contact, use the post-call model to identify customers for follow-up\n",
    "\n",
    "2. **Feature Importance**:\n",
    "   - Focus on collecting high-quality data for the most important features\n",
    "   - Consider gathering additional customer information to improve pre-call predictions\n",
    "\n",
    "3. **Model Deployment**:\n",
    "   - Implement both models in the bank's CRM system\n",
    "   - Regularly retrain models with new data to maintain performance\n",
    "   - Monitor model performance over time and adjust as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
